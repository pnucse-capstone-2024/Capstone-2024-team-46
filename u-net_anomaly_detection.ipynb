{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anomaly detection based on the U-Net model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the dataset\n",
    "\n",
    "Prepare dataset from label_n_full.csv files where n is 0, 1, 2, 3\n",
    "Next, we will seperate the data into train, validation and test sets with a ratio of 0.7 : 0.15 : 0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1445800\n",
      "1440100\n",
      "1414800\n",
      "1439900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/seyeong/anaconda3/envs/anomaly_detection/lib/python3.10/site-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14401 100\n",
      "Data split 0: train + val + test = 10120 + 2169 + 2169\n",
      "Data split 1: train + val + test = 10080 + 2160 + 2161\n",
      "Data split 2: train + val + test = 9903 + 2122 + 2123\n",
      "Data split 3: train + val + test = 10079 + 2160 + 2160\n",
      "Train data shape: (40182, 100, 3)\n",
      "Validation data shape: (8611, 100, 3)\n",
      "Test data shape: (8613, 100, 3)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "label_0 = pd.read_csv(\"data/label_0_full.csv\")\n",
    "label_1 = pd.read_csv(\"data/label_1_full.csv\")\n",
    "label_2 = pd.read_csv(\"data/label_2_full.csv\")\n",
    "label_3 = pd.read_csv(\"data/label_3_full.csv\")\n",
    "\n",
    "len_0 = len(label_0)\n",
    "len_1 = len(label_1)\n",
    "len_2 = len(label_2)\n",
    "len_3 = len(label_3)\n",
    "\n",
    "label_X = [label_0, label_1, label_2, label_3]\n",
    "rem = [len_0, len_1, len_2, len_3]\n",
    "\n",
    "for i in range(4):\n",
    "    r = rem[i] % 100\n",
    "    label_X[i] = label_X[i].iloc[:rem[i] - r]\n",
    "\n",
    "    print(len(label_X[i]))\n",
    "\n",
    "data_split_0 = np.array_split(label_X[0], len(label_X[0]) // 100)\n",
    "data_split_1 = np.array_split(label_X[1], len(label_X[1]) // 100)\n",
    "data_split_2 = np.array_split(label_X[2], len(label_X[2]) // 100)\n",
    "data_split_3 = np.array_split(label_X[3], len(label_X[3]) // 100)\n",
    "\n",
    "y_label_0 = np.zeros((len(data_split_0), 100))  \n",
    "y_label_1 = np.ones((len(data_split_1), 100))   \n",
    "y_label_2 = np.full((len(data_split_2), 100), 2)  \n",
    "y_label_3 = np.full((len(data_split_3), 100), 3)\n",
    "\n",
    "print(len(data_split_1), len(data_split_1[0]))\n",
    "\n",
    "train_ratio = 0.7\n",
    "temp_ratio = 0.3  # for both val and test combined\n",
    "val_ratio = 0.5  # 50% of temp_ratio for validation\n",
    "test_ratio = temp_ratio / 2  # same as val_ratio\n",
    "\n",
    "data_splits = [data_split_0, data_split_1, data_split_2, data_split_3]\n",
    "y_data_splits = [y_label_0, y_label_1, y_label_2, y_label_3]\n",
    "\n",
    "train_sizes = []\n",
    "train_data = []\n",
    "val_data = []\n",
    "test_data = []\n",
    "\n",
    "y_train_data = []\n",
    "y_val_data = []\n",
    "y_test_data = []\n",
    "\n",
    "for i in range(4):\n",
    "    data_len = len(data_splits[i])\n",
    "    train_size = int(data_len * train_ratio)\n",
    "    temp_size = data_len - train_size \n",
    "    val_size = int(temp_size * val_ratio)\n",
    "    \n",
    "    # Split the data\n",
    "    train_sizes.append(train_size)\n",
    "    train_data.append(data_splits[i][:train_size])\n",
    "    val_data.append(data_splits[i][train_size:train_size + val_size])\n",
    "    test_data.append(data_splits[i][train_size + val_size:])\n",
    "\n",
    "    # Split the labels\n",
    "    y_train_data.append(y_data_splits[i][:train_size])\n",
    "    y_val_data.append(y_data_splits[i][train_size:train_size + val_size])\n",
    "    y_test_data.append(y_data_splits[i][train_size + val_size:])\n",
    "\n",
    "# check the lengths of each split\n",
    "for i in range(4):\n",
    "    print(f\"Data split {i}: train + val + test =\", len(train_data[i]), \"+\", len(val_data[i]), \"+\", len(test_data[i]))\n",
    "\n",
    "# Concatenate all splits across the 4 data parts\n",
    "x_train_concat = np.concatenate(train_data, axis=0)\n",
    "x_val_concat = np.concatenate(val_data, axis=0)\n",
    "x_test_concat = np.concatenate(test_data, axis=0)\n",
    "\n",
    "y_train_concat = np.concatenate(y_train_data, axis=0)\n",
    "y_val_concat = np.concatenate(y_val_data, axis=0)\n",
    "y_test_concat = np.concatenate(y_test_data, axis=0)\n",
    "\n",
    "# Output final shapes to confirm correct splitting\n",
    "print(\"Train data shape:\", x_train_concat.shape)\n",
    "print(\"Validation data shape:\", x_val_concat.shape)\n",
    "print(\"Test data shape:\", x_test_concat.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40182, 100)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_concat[0]\n",
    "y_train_concat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert y value to one-hot encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40182, 100, 4)\n",
      "(8611, 100, 4)\n",
      "(8613, 100, 4)\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "# Convert y_train and y_valid to one-hot encoding\n",
    "y_train_one_hot = to_categorical(y_train_concat, num_classes=4) \n",
    "y_valid_one_hot = to_categorical(y_val_concat, num_classes=4)  \n",
    "y_test_one_hot = to_categorical(y_test_concat, num_classes=4) \n",
    "\n",
    "# Check the shape\n",
    "print(y_train_one_hot.shape) \n",
    "print(y_valid_one_hot.shape) \n",
    "print(y_test_one_hot.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40182, 100, 4)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_one_hot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 12, 256) (None, 12, 256)\n",
      "(None, 25, 128) (None, 25, 128)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_6       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_58 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │ input_layer_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_59 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,104</span> │ conv1d_58[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling1d_16    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_59[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_60 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">6,208</span> │ max_pooling1d_16… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_61 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">12,352</span> │ conv1d_60[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling1d_17    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_61[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_62 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">24,704</span> │ max_pooling1d_17… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_63 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">49,280</span> │ conv1d_62[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling1d_18    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_63[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_64 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">98,560</span> │ max_pooling1d_18… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_65 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">196,864</span> │ conv1d_64[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling1d_19    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_65[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_66 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">393,728</span> │ max_pooling1d_19… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_67 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">786,944</span> │ conv1d_66[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_transpose_10 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">262,400</span> │ conv1d_67[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1DTranspose</span>)   │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_10      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_transpose… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ conv1d_65[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_68 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">393,472</span> │ concatenate_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_69 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">196,864</span> │ conv1d_68[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_transpose_11 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">65,664</span> │ conv1d_69[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1DTranspose</span>)   │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ zero_padding1d_1    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_transpose… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ZeroPadding1D</span>)     │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_11      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ zero_padding1d_1… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ conv1d_63[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_70 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">98,432</span> │ concatenate_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_71 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">49,280</span> │ conv1d_70[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_transpose_12 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,448</span> │ conv1d_71[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1DTranspose</span>)   │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_12      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_transpose… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ conv1d_61[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_72 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">24,640</span> │ concatenate_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_73 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">12,352</span> │ conv1d_72[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_transpose_13 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,128</span> │ conv1d_73[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1DTranspose</span>)   │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_13      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_transpose… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ conv1d_59[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_74 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">6,176</span> │ concatenate_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_75 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,104</span> │ conv1d_74[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_76 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">132</span> │ conv1d_75[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_6       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_58 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │        \u001b[38;5;34m320\u001b[0m │ input_layer_6[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_59 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │      \u001b[38;5;34m3,104\u001b[0m │ conv1d_58[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling1d_16    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ conv1d_59[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_60 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │      \u001b[38;5;34m6,208\u001b[0m │ max_pooling1d_16… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_61 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │     \u001b[38;5;34m12,352\u001b[0m │ conv1d_60[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling1d_17    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ conv1d_61[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_62 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │     \u001b[38;5;34m24,704\u001b[0m │ max_pooling1d_17… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_63 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │     \u001b[38;5;34m49,280\u001b[0m │ conv1d_62[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling1d_18    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ conv1d_63[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_64 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │     \u001b[38;5;34m98,560\u001b[0m │ max_pooling1d_18… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_65 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │    \u001b[38;5;34m196,864\u001b[0m │ conv1d_64[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling1d_19    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ conv1d_65[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_66 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │    \u001b[38;5;34m393,728\u001b[0m │ max_pooling1d_19… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_67 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │    \u001b[38;5;34m786,944\u001b[0m │ conv1d_66[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_transpose_10 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │    \u001b[38;5;34m262,400\u001b[0m │ conv1d_67[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mConv1DTranspose\u001b[0m)   │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_10      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ conv1d_transpose… │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ conv1d_65[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_68 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │    \u001b[38;5;34m393,472\u001b[0m │ concatenate_10[\u001b[38;5;34m0\u001b[0m… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_69 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │    \u001b[38;5;34m196,864\u001b[0m │ conv1d_68[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_transpose_11 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │     \u001b[38;5;34m65,664\u001b[0m │ conv1d_69[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mConv1DTranspose\u001b[0m)   │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ zero_padding1d_1    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ conv1d_transpose… │\n",
       "│ (\u001b[38;5;33mZeroPadding1D\u001b[0m)     │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_11      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ zero_padding1d_1… │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ conv1d_63[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_70 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │     \u001b[38;5;34m98,432\u001b[0m │ concatenate_11[\u001b[38;5;34m0\u001b[0m… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_71 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │     \u001b[38;5;34m49,280\u001b[0m │ conv1d_70[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_transpose_12 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │     \u001b[38;5;34m16,448\u001b[0m │ conv1d_71[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mConv1DTranspose\u001b[0m)   │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_12      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ conv1d_transpose… │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ conv1d_61[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_72 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │     \u001b[38;5;34m24,640\u001b[0m │ concatenate_12[\u001b[38;5;34m0\u001b[0m… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_73 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │     \u001b[38;5;34m12,352\u001b[0m │ conv1d_72[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_transpose_13 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │      \u001b[38;5;34m4,128\u001b[0m │ conv1d_73[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mConv1DTranspose\u001b[0m)   │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_13      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ conv1d_transpose… │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ conv1d_59[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_74 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │      \u001b[38;5;34m6,176\u001b[0m │ concatenate_13[\u001b[38;5;34m0\u001b[0m… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_75 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │      \u001b[38;5;34m3,104\u001b[0m │ conv1d_74[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_76 (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m4\u001b[0m)    │        \u001b[38;5;34m132\u001b[0m │ conv1d_75[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,705,156</span> (10.32 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,705,156\u001b[0m (10.32 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,705,156</span> (10.32 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,705,156\u001b[0m (10.32 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "batch_size_ = len(y_train_concat)\n",
    "# Define the U-Net model\n",
    "def unet_model(input_shape=(100, 3), num_classes=4):\n",
    "    inputs = layers.Input(input_shape)\n",
    "\n",
    "    # Encoder (downsampling path)\n",
    "    conv1 = layers.Conv1D(32, kernel_size=3, activation='relu', padding='same')(inputs)\n",
    "    conv1 = layers.Conv1D(32, kernel_size=3, activation='relu', padding='same')(conv1)\n",
    "    pool1 = layers.MaxPooling1D(2)(conv1)\n",
    "\n",
    "    conv2 = layers.Conv1D(64, kernel_size=3, activation='relu', padding='same')(pool1)\n",
    "    conv2 = layers.Conv1D(64, kernel_size=3, activation='relu', padding='same')(conv2)\n",
    "    pool2 = layers.MaxPooling1D(2)(conv2)\n",
    "\n",
    "    conv3 = layers.Conv1D(128,  kernel_size=3, activation='relu', padding='same')(pool2)\n",
    "    conv3 = layers.Conv1D(128,  kernel_size=3, activation='relu', padding='same')(conv3)\n",
    "    pool3 = layers.MaxPooling1D(pool_size=2)(conv3)\n",
    "\n",
    "    conv4 = layers.Conv1D(256,  kernel_size=3, activation='relu', padding='same')(pool3)\n",
    "    conv4 = layers.Conv1D(256,  kernel_size=3, activation='relu', padding='same')(conv4)\n",
    "    pool4 = layers.MaxPooling1D(pool_size=2)(conv4)\n",
    "\n",
    "    # Bottleneck\n",
    "    conv5 = layers.Conv1D(512,  kernel_size=3, activation='relu', padding='same')(pool4)\n",
    "    conv5 = layers.Conv1D(512,  kernel_size=3, activation='relu', padding='same')(conv5)\n",
    "\n",
    "    # Decoder (upsampling path)\n",
    "    up6 = layers.Conv1DTranspose(256, kernel_size=2, strides=2, padding='same')(conv5)\n",
    "    print(up6.shape, conv4.shape)\n",
    "    up6 = layers.concatenate([up6, conv4])\n",
    "\n",
    "    conv6 = layers.Conv1D(256,  kernel_size=3, activation='relu', padding='same')(up6)\n",
    "    conv6 = layers.Conv1D(256,  kernel_size=3, activation='relu', padding='same')(conv6)\n",
    "\n",
    "    up7 = layers.Conv1DTranspose(128, kernel_size=2, strides=2, padding='same')(conv6)\n",
    "    up7 = layers.ZeroPadding1D(padding=(1, 0))(up7)\n",
    "    print(up7.shape, conv3.shape)\n",
    "    up7 = layers.concatenate([up7, conv3])\n",
    "    conv7 = layers.Conv1D(128,  kernel_size=3, activation='relu', padding='same')(up7)\n",
    "    conv7 = layers.Conv1D(128,  kernel_size=3, activation='relu', padding='same')(conv7)\n",
    "\n",
    "    up8 = layers.Conv1DTranspose(64, kernel_size=2, strides=2, padding='same')(conv7)\n",
    "    up8 = layers.concatenate([up8, conv2])\n",
    "    conv8 = layers.Conv1D(64,  kernel_size=3, activation='relu', padding='same')(up8)\n",
    "    conv8 = layers.Conv1D(64,  kernel_size=3, activation='relu', padding='same')(conv8)\n",
    "\n",
    "    up9 = layers.Conv1DTranspose(32, kernel_size=2, strides=2, padding='same')(conv8)\n",
    "    up9 = layers.concatenate([up9, conv1])\n",
    "    conv9 = layers.Conv1D(32,  kernel_size=3, activation='relu', padding='same')(up9)\n",
    "    conv9 = layers.Conv1D(32,  kernel_size=3, activation='relu', padding='same')(conv9)\n",
    "\n",
    "    # Output layer for multi-class classification (4 classes)\n",
    "    outputs = layers.Conv1D(num_classes, kernel_size=1, activation='softmax')(conv9)\n",
    "\n",
    "    # Model compilation\n",
    "    model = models.Model(inputs=[inputs], outputs=[outputs])\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "# Instantiate and view the model summary\n",
    "model = unet_model()\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "A `Concatenate` layer requires inputs with matching shapes except for the concatenation axis. Received: input_shape=[(None, 24, 64), (None, 50, 64)]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[61], line 64\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m# Instantiate and view the model summary\u001b[39;00m\n\u001b[0;32m---> 64\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43munet_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m model\u001b[38;5;241m.\u001b[39msummary()\n",
      "Cell \u001b[0;32mIn[61], line 45\u001b[0m, in \u001b[0;36munet_model\u001b[0;34m(input_shape, num_classes)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# conv4 = layers.Conv1D(256,  kernel_size=3, activation='relu', padding='same')(pool3)\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# conv4 = layers.Conv1D(256,  kernel_size=3, activation='relu', padding='same')(conv4)\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# pool4 = layers.MaxPooling1D(pool_size=2)(conv4)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# conv7 = layers.Conv1D(128,  kernel_size=3, activation='relu', padding='same')(up7)\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# conv7 = layers.Conv1D(128,  kernel_size=3, activation='relu', padding='same')(conv7)\u001b[39;00m\n\u001b[1;32m     44\u001b[0m up8 \u001b[38;5;241m=\u001b[39m layers\u001b[38;5;241m.\u001b[39mConv1DTranspose(\u001b[38;5;241m64\u001b[39m, kernel_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, strides\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msame\u001b[39m\u001b[38;5;124m'\u001b[39m)(pool3)\n\u001b[0;32m---> 45\u001b[0m up8 \u001b[38;5;241m=\u001b[39m \u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mup8\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconv2\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m conv8 \u001b[38;5;241m=\u001b[39m layers\u001b[38;5;241m.\u001b[39mConv1D(\u001b[38;5;241m64\u001b[39m,  kernel_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msame\u001b[39m\u001b[38;5;124m'\u001b[39m)(up8)\n\u001b[1;32m     47\u001b[0m conv8 \u001b[38;5;241m=\u001b[39m layers\u001b[38;5;241m.\u001b[39mConv1D(\u001b[38;5;241m64\u001b[39m,  kernel_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msame\u001b[39m\u001b[38;5;124m'\u001b[39m)(conv8)\n",
      "File \u001b[0;32m~/anaconda3/envs/anomaly_detection/lib/python3.10/site-packages/keras/src/layers/merging/concatenate.py:176\u001b[0m, in \u001b[0;36mconcatenate\u001b[0;34m(inputs, axis, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;129m@keras_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeras.layers.concatenate\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconcatenate\u001b[39m(inputs, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    166\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Functional interface to the `Concatenate` layer.\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \n\u001b[1;32m    168\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;124;03m        A tensor, the concatenation of the inputs alongside axis `axis`.\u001b[39;00m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 176\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mConcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/anomaly_detection/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/envs/anomaly_detection/lib/python3.10/site-packages/keras/src/layers/merging/concatenate.py:97\u001b[0m, in \u001b[0;36mConcatenate.build\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m     91\u001b[0m         unique_dims \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(\n\u001b[1;32m     92\u001b[0m             shape[axis]\n\u001b[1;32m     93\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m shape \u001b[38;5;129;01min\u001b[39;00m shape_set\n\u001b[1;32m     94\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m shape[axis] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     95\u001b[0m         )\n\u001b[1;32m     96\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(unique_dims) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 97\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(err_msg)\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuilt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: A `Concatenate` layer requires inputs with matching shapes except for the concatenation axis. Received: input_shape=[(None, 24, 64), (None, 50, 64)]"
     ]
    }
   ],
   "source": [
    "# model2 \n",
    "\n",
    "# Define the U-Net model\n",
    "def unet_model(input_shape=(100, 3), num_classes=4):\n",
    "    inputs = layers.Input(input_shape)\n",
    "\n",
    "    # Encoder (downsampling path)\n",
    "    conv1 = layers.Conv1D(32, kernel_size=3, activation='relu', padding='same')(inputs)\n",
    "    conv1 = layers.Conv1D(32, kernel_size=3, activation='relu', padding='same')(conv1)\n",
    "    pool1 = layers.MaxPooling1D(2)(conv1)\n",
    "\n",
    "    conv2 = layers.Conv1D(64, kernel_size=3, activation='relu', padding='same')(pool1)\n",
    "    conv2 = layers.Conv1D(64, kernel_size=3, activation='relu', padding='same')(conv2)\n",
    "    pool2 = layers.MaxPooling1D(2)(conv2)\n",
    "\n",
    "    conv3 = layers.Conv1D(128,  kernel_size=3, activation='relu', padding='same')(pool2)\n",
    "    conv3 = layers.Conv1D(128,  kernel_size=3, activation='relu', padding='same')(conv3)\n",
    "\n",
    "\n",
    "\n",
    "    up8 = layers.Conv1DTranspose(64, kernel_size=2, strides=2, padding='same')(conv3)\n",
    "    up8 = layers.concatenate([up8, conv2])\n",
    "    conv8 = layers.Conv1D(64,  kernel_size=3, activation='relu', padding='same')(up8)\n",
    "    conv8 = layers.Conv1D(64,  kernel_size=3, activation='relu', padding='same')(conv8)\n",
    "\n",
    "    up9 = layers.Conv1DTranspose(32, kernel_size=2, strides=2, padding='same')(conv8)\n",
    "    up9 = layers.concatenate([up9, conv1])\n",
    "    conv9 = layers.Conv1D(32,  kernel_size=3, activation='relu', padding='same')(up9)\n",
    "    conv9 = layers.Conv1D(32,  kernel_size=3, activation='relu', padding='same')(conv9)\n",
    "\n",
    "    # Output layer for multi-class classification (4 classes)\n",
    "    outputs = layers.Conv1D(num_classes, kernel_size=1, activation='softmax')(conv9)\n",
    "\n",
    "    # Model compilation\n",
    "    model = models.Model(inputs=[inputs], outputs=[outputs])\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "# Instantiate and view the model summary\n",
    "model = unet_model()\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_5\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_5\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_11      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_116 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │ input_layer_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_117 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,104</span> │ conv1d_116[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling1d_29    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_117[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_118 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">6,208</span> │ max_pooling1d_29… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_119 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">12,352</span> │ conv1d_118[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling1d_30    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_119[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_120 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">24,704</span> │ max_pooling1d_30… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_121 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">49,280</span> │ conv1d_120[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_transpose_21 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,448</span> │ conv1d_121[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1DTranspose</span>)   │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_21      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_transpose… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ conv1d_119[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_122 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">24,640</span> │ concatenate_21[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_123 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">12,352</span> │ conv1d_122[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_transpose_22 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,128</span> │ conv1d_123[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1DTranspose</span>)   │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_22      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_transpose… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ conv1d_117[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_124 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">6,176</span> │ concatenate_22[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_125 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,104</span> │ conv1d_124[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_126 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">132</span> │ conv1d_125[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_11      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_116 (\u001b[38;5;33mConv1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │        \u001b[38;5;34m320\u001b[0m │ input_layer_11[\u001b[38;5;34m0\u001b[0m… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_117 (\u001b[38;5;33mConv1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │      \u001b[38;5;34m3,104\u001b[0m │ conv1d_116[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling1d_29    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ conv1d_117[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_118 (\u001b[38;5;33mConv1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │      \u001b[38;5;34m6,208\u001b[0m │ max_pooling1d_29… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_119 (\u001b[38;5;33mConv1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │     \u001b[38;5;34m12,352\u001b[0m │ conv1d_118[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling1d_30    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ conv1d_119[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_120 (\u001b[38;5;33mConv1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │     \u001b[38;5;34m24,704\u001b[0m │ max_pooling1d_30… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_121 (\u001b[38;5;33mConv1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │     \u001b[38;5;34m49,280\u001b[0m │ conv1d_120[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_transpose_21 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │     \u001b[38;5;34m16,448\u001b[0m │ conv1d_121[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mConv1DTranspose\u001b[0m)   │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_21      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ conv1d_transpose… │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ conv1d_119[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_122 (\u001b[38;5;33mConv1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │     \u001b[38;5;34m24,640\u001b[0m │ concatenate_21[\u001b[38;5;34m0\u001b[0m… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_123 (\u001b[38;5;33mConv1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │     \u001b[38;5;34m12,352\u001b[0m │ conv1d_122[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_transpose_22 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │      \u001b[38;5;34m4,128\u001b[0m │ conv1d_123[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mConv1DTranspose\u001b[0m)   │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_22      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ conv1d_transpose… │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ conv1d_117[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_124 (\u001b[38;5;33mConv1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │      \u001b[38;5;34m6,176\u001b[0m │ concatenate_22[\u001b[38;5;34m0\u001b[0m… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_125 (\u001b[38;5;33mConv1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │      \u001b[38;5;34m3,104\u001b[0m │ conv1d_124[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_126 (\u001b[38;5;33mConv1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m4\u001b[0m)    │        \u001b[38;5;34m132\u001b[0m │ conv1d_125[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">162,948</span> (636.52 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m162,948\u001b[0m (636.52 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">162,948</span> (636.52 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m162,948\u001b[0m (636.52 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras import layers, models, regularizers\n",
    "\n",
    "# Define the U-Net model with L1 and L2 regularization\n",
    "def unet_model(input_shape=(100, 3), num_classes=4, l1_lambda=1e-2, l2_lambda=1e-2):\n",
    "    inputs = layers.Input(input_shape)\n",
    "\n",
    "    # Encoder (downsampling path)\n",
    "    conv1 = layers.Conv1D(32, kernel_size=3, activation='relu', padding='same',\n",
    "                          kernel_regularizer=regularizers.l1_l2(l1=l1_lambda, l2=l2_lambda))(inputs)\n",
    "    conv1 = layers.Conv1D(32, kernel_size=3, activation='relu', padding='same',\n",
    "                          kernel_regularizer=regularizers.l1_l2(l1=l1_lambda, l2=l2_lambda))(conv1)\n",
    "    pool1 = layers.MaxPooling1D(2)(conv1)\n",
    "\n",
    "    conv2 = layers.Conv1D(64, kernel_size=3, activation='relu', padding='same',\n",
    "                          kernel_regularizer=regularizers.l1_l2(l1=l1_lambda, l2=l2_lambda))(pool1)\n",
    "    conv2 = layers.Conv1D(64, kernel_size=3, activation='relu', padding='same',\n",
    "                          kernel_regularizer=regularizers.l1_l2(l1=l1_lambda, l2=l2_lambda))(conv2)\n",
    "    pool2 = layers.MaxPooling1D(2)(conv2)\n",
    "\n",
    "    conv3 = layers.Conv1D(128, kernel_size=3, activation='relu', padding='same',\n",
    "                          kernel_regularizer=regularizers.l1_l2(l1=l1_lambda, l2=l2_lambda))(pool2)\n",
    "    conv3 = layers.Conv1D(128, kernel_size=3, activation='relu', padding='same',\n",
    "                          kernel_regularizer=regularizers.l1_l2(l1=l1_lambda, l2=l2_lambda))(conv3)\n",
    "\n",
    "    up8 = layers.Conv1DTranspose(64, kernel_size=2, strides=2, padding='same')(conv3)\n",
    "    up8 = layers.concatenate([up8, conv2])\n",
    "    conv8 = layers.Conv1D(64, kernel_size=3, activation='relu', padding='same',\n",
    "                          kernel_regularizer=regularizers.l1_l2(l1=l1_lambda, l2=l2_lambda))(up8)\n",
    "    conv8 = layers.Conv1D(64, kernel_size=3, activation='relu', padding='same',\n",
    "                          kernel_regularizer=regularizers.l1_l2(l1=l1_lambda, l2=l2_lambda))(conv8)\n",
    "\n",
    "    up9 = layers.Conv1DTranspose(32, kernel_size=2, strides=2, padding='same')(conv8)\n",
    "    up9 = layers.concatenate([up9, conv1])\n",
    "    conv9 = layers.Conv1D(32, kernel_size=3, activation='relu', padding='same',\n",
    "                          kernel_regularizer=regularizers.l1_l2(l1=l1_lambda, l2=l2_lambda))(up9)\n",
    "    conv9 = layers.Conv1D(32, kernel_size=3, activation='relu', padding='same',\n",
    "                          kernel_regularizer=regularizers.l1_l2(l1=l1_lambda, l2=l2_lambda))(conv9)\n",
    "\n",
    "    # Output layer for multi-class classification (4 classes)\n",
    "    outputs = layers.Conv1D(num_classes, kernel_size=1, activation='softmax')(conv9)\n",
    "\n",
    "    # Model compilation\n",
    "    model = models.Model(inputs=[inputs], outputs=[outputs])\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "# Instantiate and view the model summary\n",
    "model = unet_model()\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "early_stop = EarlyStopping(monitor='loss', patience=1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m1256/1256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 13ms/step - accuracy: 0.2488 - loss: 1.5627 - val_accuracy: 0.2508 - val_loss: 1.5663\n",
      "Epoch 2/20\n",
      "\u001b[1m1256/1256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 13ms/step - accuracy: 0.2488 - loss: 1.5671 - val_accuracy: 0.2519 - val_loss: 1.5684\n",
      "Epoch 2: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x_train_concat, y_train_one_hot,  # Ensure y_train is one-hot encoded for multi-class\n",
    "    epochs=20,\n",
    "    batch_size=32,\n",
    "    validation_data=(x_val_concat, y_valid_one_hot),\n",
    "    verbose=1,\n",
    "    # class_weight=class_weights_dict,\n",
    "    callbacks=[early_stop]\n",
    ")\n",
    "\n",
    "# Save the model\n",
    "model.save(\"u_net_v5.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4027 - loss: 6.9615\n",
      "3.0094895362854004\n",
      "0.7359337210655212\n"
     ]
    }
   ],
   "source": [
    "# model2\n",
    "loss, accuracy = model.evaluate(x_test_concat, y_test_one_hot, verbose=1)\n",
    "print(loss)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.2817 - loss: 13.3503\n",
      "7.1685919761657715\n",
      "0.4819646179676056\n"
     ]
    }
   ],
   "source": [
    "# model3\n",
    "loss, accuracy = model.evaluate(x_test_concat, y_test_one_hot, verbose=1)\n",
    "print(loss)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m270/270\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0364 - loss: 1.4042\n",
      "1.4042704105377197\n",
      "0.2507837116718292\n"
     ]
    }
   ],
   "source": [
    "# model4 (saved as u_net_v3.h5)\n",
    "loss, accuracy = model.evaluate(x_test_concat, y_test_one_hot, verbose=1)\n",
    "print(loss)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8613, 100)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_classes = np.argmax(y_pred, axis=-1)\n",
    "\n",
    "y_pred_classes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8613, 100)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_concat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.01      0.00      0.00    216900\n",
      "         1.0       1.00      1.00      1.00    216100\n",
      "         2.0       1.00      1.00      1.00    212300\n",
      "         3.0       0.49      0.95      0.64    216000\n",
      "\n",
      "    accuracy                           0.74    861300\n",
      "   macro avg       0.62      0.74      0.66    861300\n",
      "weighted avg       0.62      0.74      0.66    861300\n",
      "\n",
      "혼동 행렬:\n",
      "[[    93     90     27 216690]\n",
      " [     8 215954      0    138]\n",
      " [   302     30 211751    217]\n",
      " [  9856     40     42 206062]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "y_test_flatten = y_test_concat.flatten()\n",
    "y_pred_flatten = y_pred_classes.flatten()\n",
    "\n",
    "print(classification_report(y_test_flatten, y_pred_flatten))\n",
    "\n",
    "# 혼동 행렬 계산\n",
    "cm = confusion_matrix(y_test_flatten, y_pred_flatten)\n",
    "\n",
    "# 혼동 행렬 출력\n",
    "print(\"혼동 행렬:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DTW Distance: 30.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from dtaidistance import dtw\n",
    "\n",
    "\n",
    "# DTW 거리 계산\n",
    "distance = dtw.distance(y_test_concat[0], y_pred_classes[0])\n",
    "print(f\"DTW Distance: {distance}\")\n",
    "\n",
    "# 최적의 매칭 경로 시각화\n",
    "import matplotlib.pyplot as plt\n",
    "from dtaidistance import dtw_visualisation as dtwvis\n",
    "\n",
    "dtwvis.plot_warping(y_test_concat[0], y_pred_classes[0], dtw.warping_path(y_test_concat[0], y_pred_classes[0]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Scores for each sequence: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.038461538461538464, 0.0, 0.0196078431372549, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.031746031746031744, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0196078431372549, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.047619047619047616, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0196078431372549, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02912621359223301, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.025641025641025644, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02912621359223301, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0196078431372549, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.009900990099009901, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11504424778761062, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.013071895424836602, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.025641025641025644, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0196078431372549, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0196078431372549, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05660377358490566, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01941747572815534, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05660377358490566, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09090909090909091, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.038461538461538464, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0196078431372549, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05660377358490566, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3282571912013536, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.494949494949495, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.494949494949495, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.494949494949495, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.494949494949495, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.494949494949495, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.494949494949495, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.494949494949495, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4845360824742268, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.46236559139784944, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.494949494949495, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.494949494949495, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.494949494949495, 1.0, 1.0, 1.0, 1.0, 0.494949494949495, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4845360824742268, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.494949494949495, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.494949494949495, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.494949494949495, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.47368421052631576, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.46236559139784944, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4594594594594595, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4897959183673469, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.47368421052631576, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.49238578680203043, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.494949494949495, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.494949494949495, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.494949494949495, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.48717948717948717, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.494949494949495, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3157894736842105, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.494949494949495, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4791666666666667, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3247863247863248, 1.0, 0.49748743718592964, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.494949494949495, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.49748743718592964, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.49748743718592964, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3282571912013536, 1.0, 1.0, 0.49748743718592964, 1.0, 1.0, 1.0, 1.0, 1.0, 0.49748743718592964, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3282571912013536, 1.0, 1.0, 0.494949494949495, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3282571912013536, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.49748743718592964, 1.0, 1.0, 1.0, 1.0, 0.3282571912013536, 0.49748743718592964, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.49238578680203043, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.494949494949495, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.494949494949495, 1.0, 0.49748743718592964, 0.49748743718592964, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.49748743718592964, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.49748743718592964, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.494949494949495, 1.0, 1.0, 0.49748743718592964, 1.0, 0.49748743718592964, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.494949494949495, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.49748743718592964, 1.0, 0.3247863247863248, 1.0, 1.0, 0.49748743718592964, 1.0, 0.22826086956521738, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.494949494949495, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.494949494949495, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.494949494949495, 1.0, 1.0, 0.494949494949495, 1.0, 1.0, 1.0, 0.494949494949495, 1.0, 1.0, 0.49748743718592964, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.49748743718592964, 1.0, 1.0, 1.0, 1.0, 0.48717948717948717, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.49748743718592964, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.494949494949495, 1.0, 1.0, 1.0, 0.494949494949495, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.49748743718592964, 1.0, 1.0, 1.0, 1.0, 0.49748743718592964, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3282571912013536, 1.0, 1.0, 1.0, 1.0, 0.3282571912013536, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.49748743718592964, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.49748743718592964, 0.3082437275985663, 1.0, 1.0, 1.0, 0.49748743718592964, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.49748743718592964, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.49748743718592964, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.49748743718592964, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.49748743718592964, 1.0, 1.0, 1.0, 1.0, 1.0, 0.49748743718592964, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.49748743718592964, 1.0, 1.0, 1.0, 1.0, 0.3247863247863248, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.49748743718592964, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.49748743718592964, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.49748743718592964, 1.0, 0.49748743718592964, 1.0, 0.494949494949495, 1.0, 1.0, 0.49748743718592964, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.494949494949495, 1.0, 1.0, 1.0, 1.0, 0.4791666666666667, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.49748743718592964, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.21264367816091953, 1.0, 0.19879518072289157, 1.0, 0.49748743718592964, 1.0, 1.0, 1.0, 1.0, 1.0, 0.494949494949495, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.494949494949495, 1.0, 1.0, 1.0, 1.0, 1.0, 0.49748743718592964, 1.0, 0.49748743718592964, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.494949494949495, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.49748743718592964, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.48717948717948717, 0.4897959183673469, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.494949494949495, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.494949494949495, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.49748743718592964, 1.0, 1.0, 1.0, 1.0, 1.0, 0.494949494949495, 1.0, 1.0, 1.0, 1.0, 1.0, 0.49748743718592964, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.49238578680203043, 1.0, 1.0, 1.0, 0.494949494949495, 1.0, 1.0, 1.0, 1.0, 0.49748743718592964, 1.0, 1.0, 1.0, 0.49238578680203043, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.49748743718592964, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.49748743718592964, 1.0, 1.0, 0.49748743718592964, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.49748743718592964, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.49748743718592964, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.49748743718592964, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.49748743718592964, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3282571912013536, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.49748743718592964, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.49748743718592964, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.49748743718592964, 1.0, 1.0, 1.0, 0.49748743718592964, 1.0, 1.0, 1.0, 1.0, 1.0, 0.49748743718592964, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.32653061224489793, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.49748743718592964, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3282571912013536, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.49748743718592964, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.49748743718592964, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.494949494949495, 1.0, 1.0, 0.49748743718592964, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.49748743718592964, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.49748743718592964, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.49748743718592964, 1.0, 1.0, 1.0, 1.0, 0.49748743718592964, 1.0, 1.0, 0.49748743718592964, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.49748743718592964, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.494949494949495, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.494949494949495, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.48717948717948717, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4845360824742268, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.49748743718592964, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.49748743718592964, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.30036630036630035, 1.0, 1.0, 1.0, 0.32996632996632996, 1.0, 1.0, 1.0, 0.49748743718592964, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.49748743718592964, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.49748743718592964, 1.0, 0.49748743718592964, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.494949494949495, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.48186528497409326, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.49748743718592964, 1.0, 1.0, 0.4845360824742268, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.494949494949495, 0.3282571912013536, 1.0, 0.3282571912013536, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.49748743718592964, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.494949494949495, 1.0, 0.3230240549828179, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.494949494949495, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.49748743718592964, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3282571912013536, 1.0, 0.1951219512195122, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.49748743718592964, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.49748743718592964, 1.0, 1.0, 1.0, 1.0, 1.0, 0.49748743718592964, 1.0, 1.0, 1.0, 1.0, 0.49748743718592964, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.49748743718592964, 1.0, 1.0, 1.0, 0.49748743718592964, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.49748743718592964, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.32996632996632996, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.49748743718592964, 1.0, 1.0, 0.49238578680203043, 0.4708994708994709, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.494949494949495, 1.0, 1.0, 1.0, 1.0, 0.3157894736842105, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.494949494949495, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.48717948717948717, 1.0, 1.0, 1.0, 0.49238578680203043, 1.0, 1.0, 1.0, 1.0, 1.0, 0.49748743718592964, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.494949494949495, 1.0, 1.0, 1.0, 1.0, 1.0, 0.49748743718592964, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.49748743718592964, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.49748743718592964, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.49748743718592964, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.49748743718592964, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.49748743718592964, 0.49748743718592964, 1.0, 1.0, 1.0, 0.494949494949495, 0.49748743718592964, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.494949494949495, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.49748743718592964, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.29422718808193665, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.45054945054945056, 1.0, 0.3282571912013536, 1.0, 1.0, 1.0, 1.0, 0.48717948717948717, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.49748743718592964, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.49748743718592964, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.48186528497409326, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3230240549828179, 1.0, 0.4791666666666667, 1.0, 1.0, 0.494949494949495, 0.32124352331606215, 0.49748743718592964, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3282571912013536, 0.49748743718592964, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.49748743718592964, 0.494949494949495, 1.0, 1.0, 1.0, 1.0, 1.0, 0.32996632996632996, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4791666666666667, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4845360824742268, 0.46236559139784944, 1.0, 1.0, 1.0, 1.0, 1.0, 0.48186528497409326, 0.4152046783625731, 1.0, 1.0, 1.0, 1.0, 1.0, 0.44751381215469616, 1.0, 1.0, 1.0, 0.4708994708994709, 0.49238578680203043, 0.494949494949495, 1.0, 1.0, 0.4845360824742268, 1.0, 0.48186528497409326, 0.494949494949495, 1.0, 1.0, 1.0, 0.494949494949495, 0.47643979057591623, 0.453551912568306, 1.0, 0.47643979057591623, 1.0, 1.0, 0.4791666666666667, 0.46524064171123, 1.0, 1.0, 1.0, 0.4897959183673469, 0.46808510638297873, 1.0, 1.0, 0.494949494949495, 1.0, 0.4117647058823529, 0.4845360824742268, 0.49238578680203043, 1.0, 1.0, 0.494949494949495, 0.4845360824742268, 1.0, 1.0, 1.0, 1.0, 1.0, 0.46808510638297873, 0.49238578680203043, 1.0, 0.42857142857142855, 1.0, 1.0, 0.46808510638297873, 0.48717948717948717, 1.0, 0.46236559139784944, 1.0, 0.4845360824742268, 0.4845360824742268, 1.0, 0.47368421052631576, 1.0, 0.4594594594594595, 0.4845360824742268, 0.46236559139784944, 1.0, 0.4897959183673469, 1.0, 0.39759036144578314, 0.3902439024390244, 0.45054945054945056, 0.4708994708994709, 1.0, 1.0, 1.0, 0.45054945054945056, 0.4117647058823529, 1.0, 0.4444444444444444, 1.0, 1.0, 1.0, 0.47368421052631576, 1.0, 1.0, 1.0, 0.494949494949495, 1.0, 1.0, 1.0, 0.43820224719101125, 1.0, 1.0, 1.0, 0.494949494949495, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.441340782122905, 1.0, 0.4791666666666667, 1.0, 0.47643979057591623, 1.0, 0.49238578680203043, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4845360824742268, 0.4845360824742268, 0.4845360824742268, 0.494949494949495, 1.0, 1.0, 1.0, 0.48186528497409326, 1.0, 1.0, 0.4845360824742268, 1.0, 1.0, 1.0, 0.4897959183673469, 0.4845360824742268, 0.46808510638297873, 1.0, 1.0, 0.4845360824742268, 1.0, 0.46808510638297873, 1.0, 1.0, 0.494949494949495, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4897959183673469, 1.0, 0.46524064171123, 1.0, 0.4350282485875706, 1.0, 1.0, 0.48717948717948717, 1.0, 0.45652173913043476, 1.0, 0.45652173913043476, 1.0, 1.0, 1.0, 0.48186528497409326, 1.0, 0.4708994708994709, 0.494949494949495, 1.0, 1.0, 0.47643979057591623, 1.0, 0.4845360824742268, 1.0, 0.4897959183673469, 0.47368421052631576, 0.4350282485875706, 0.494949494949495, 1.0, 0.4845360824742268, 0.49238578680203043, 1.0, 1.0, 0.4845360824742268, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.42196531791907516, 1.0, 1.0, 1.0, 0.46808510638297873, 0.47368421052631576, 1.0, 0.45652173913043476, 1.0, 0.4791666666666667, 0.47643979057591623, 1.0, 0.46808510638297873, 0.4708994708994709, 0.494949494949495, 0.47643979057591623, 1.0, 1.0, 1.0, 1.0, 0.42857142857142855, 0.46524064171123, 0.4897959183673469, 1.0, 1.0, 1.0, 0.47368421052631576, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4791666666666667, 0.43820224719101125, 0.48186528497409326, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.49748743718592964, 0.49238578680203043, 1.0, 1.0, 0.49238578680203043, 0.4117647058823529, 0.4897959183673469, 0.4791666666666667, 1.0, 0.46236559139784944, 1.0, 0.49238578680203043, 1.0, 1.0, 1.0, 1.0, 0.494949494949495, 1.0, 0.49748743718592964, 1.0, 0.4708994708994709, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.494949494949495, 0.39759036144578314, 1.0, 0.44751381215469616, 0.494949494949495, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.49748743718592964, 1.0, 0.4186046511627907, 1.0, 0.48186528497409326, 0.494949494949495, 0.49748743718592964, 1.0, 1.0, 1.0, 0.47643979057591623, 1.0, 0.48717948717948717, 1.0, 1.0, 0.4791666666666667, 1.0, 1.0, 0.441340782122905, 0.4117647058823529, 1.0, 0.46808510638297873, 1.0, 1.0, 1.0, 0.45652173913043476, 0.4845360824742268, 1.0, 0.40476190476190477, 1.0, 1.0, 1.0, 0.4594594594594595, 0.49238578680203043, 1.0, 1.0, 0.45652173913043476, 1.0, 0.4897959183673469, 0.4845360824742268, 0.40119760479041916, 0.4791666666666667, 1.0, 0.4318181818181818, 0.48717948717948717, 1.0, 1.0, 0.4444444444444444, 1.0, 1.0, 1.0, 1.0, 0.441340782122905, 1.0, 1.0, 1.0, 1.0, 0.43820224719101125, 0.48186528497409326, 1.0, 0.49238578680203043, 0.49748743718592964, 1.0, 0.48717948717948717, 1.0, 0.48717948717948717, 0.494949494949495, 1.0, 1.0, 0.453551912568306, 1.0, 0.4897959183673469, 1.0, 1.0, 0.31016042780748665, 0.46808510638297873, 1.0, 1.0, 0.494949494949495, 0.40828402366863903, 1.0, 0.47368421052631576, 0.4845360824742268, 1.0, 1.0, 0.47368421052631576, 0.48717948717948717, 0.49238578680203043, 0.3939393939393939, 1.0, 0.48186528497409326, 1.0, 1.0, 0.42857142857142855, 0.4845360824742268, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.45652173913043476, 0.494949494949495, 0.4845360824742268, 1.0, 1.0, 1.0, 1.0, 1.0, 0.48717948717948717, 0.45054945054945056, 1.0, 0.34210526315789475, 1.0, 1.0, 1.0, 1.0, 0.4791666666666667, 1.0, 1.0, 0.4318181818181818, 0.4897959183673469, 1.0, 1.0, 1.0, 0.494949494949495, 0.42857142857142855, 1.0, 0.4845360824742268, 0.3710691823899371, 0.4897959183673469, 0.4897959183673469, 0.4845360824742268, 1.0, 0.4897959183673469, 1.0, 1.0, 1.0, 1.0, 1.0, 0.494949494949495, 0.45054945054945056, 1.0, 1.0, 1.0, 0.43820224719101125, 0.45652173913043476, 0.4350282485875706, 0.42528735632183906, 0.49238578680203043, 0.42196531791907516, 1.0, 1.0, 0.2813102119460501, 1.0, 0.42528735632183906, 0.494949494949495, 1.0, 1.0, 1.0, 1.0, 0.49748743718592964, 1.0, 0.43820224719101125, 1.0, 0.4791666666666667, 1.0, 1.0, 0.47368421052631576, 0.49238578680203043, 0.45652173913043476, 0.46236559139784944, 0.4845360824742268, 1.0, 0.49748743718592964, 0.494949494949495, 0.48186528497409326, 1.0, 0.494949494949495, 1.0, 0.30036630036630035, 1.0, 1.0, 0.4117647058823529, 1.0, 1.0, 0.44751381215469616, 0.42857142857142855, 1.0, 1.0, 0.4845360824742268, 1.0, 1.0, 0.47643979057591623, 0.494949494949495, 1.0, 0.48186528497409326, 1.0, 0.453551912568306, 1.0, 1.0, 1.0, 0.48717948717948717, 1.0, 0.47368421052631576, 0.43820224719101125, 1.0, 1.0, 0.49748743718592964, 0.46808510638297873, 0.494949494949495, 1.0, 1.0, 1.0, 0.494949494949495, 1.0, 1.0, 0.35064935064935066, 0.47643979057591623, 0.48717948717948717, 1.0, 0.42196531791907516, 1.0, 0.46236559139784944, 1.0, 0.4791666666666667, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4845360824742268, 1.0, 0.43820224719101125, 1.0, 0.4708994708994709, 1.0, 1.0, 1.0, 1.0, 0.494949494949495, 1.0, 1.0, 0.4897959183673469, 1.0, 1.0, 0.47368421052631576, 0.49748743718592964, 0.49748743718592964, 0.4897959183673469, 1.0, 0.494949494949495, 1.0, 0.4350282485875706, 1.0, 0.44751381215469616, 0.47643979057591623, 1.0, 1.0, 1.0, 0.49748743718592964, 1.0, 1.0, 0.48717948717948717, 0.4318181818181818, 1.0, 1.0, 1.0, 1.0, 0.42196531791907516, 0.494949494949495, 1.0, 0.48717948717948717, 1.0, 0.43820224719101125, 1.0, 1.0, 1.0, 0.4897959183673469, 1.0, 0.49748743718592964, 1.0, 1.0, 1.0, 1.0, 0.494949494949495, 0.46808510638297873, 1.0, 0.45054945054945056, 0.37888198757763975, 1.0, 1.0, 0.4708994708994709, 0.494949494949495, 0.47368421052631576, 0.4117647058823529, 1.0, 1.0, 1.0, 0.46236559139784944, 0.47368421052631576, 1.0, 1.0, 1.0, 0.4791666666666667, 0.44751381215469616, 0.46808510638297873, 1.0, 0.43820224719101125, 1.0, 1.0, 0.4845360824742268, 0.39759036144578314, 0.4897959183673469, 1.0, 1.0, 0.3670886075949367, 1.0, 1.0, 0.441340782122905, 0.43820224719101125, 1.0, 1.0, 1.0, 0.48717948717948717, 1.0, 0.441340782122905, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.43820224719101125, 1.0, 0.48186528497409326, 1.0, 1.0, 1.0, 0.4186046511627907, 1.0, 0.45054945054945056, 1.0, 1.0, 0.4708994708994709, 0.4791666666666667, 1.0, 1.0, 1.0, 0.46808510638297873, 0.46524064171123, 1.0, 1.0, 1.0, 1.0, 0.49748743718592964, 0.48717948717948717, 0.46808510638297873, 0.4117647058823529, 1.0, 0.46236559139784944, 1.0, 1.0, 1.0, 1.0, 1.0, 0.43820224719101125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.34210526315789475, 0.40828402366863903, 1.0, 1.0, 0.494949494949495, 0.49748743718592964, 1.0, 0.39759036144578314, 1.0, 0.44751381215469616, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4897959183673469, 0.34210526315789475, 0.2698412698412698, 0.37888198757763975, 0.45054945054945056, 1.0, 0.48717948717948717, 1.0, 0.4708994708994709, 1.0, 0.4845360824742268, 0.47368421052631576, 0.494949494949495, 1.0, 1.0, 1.0, 0.4186046511627907, 0.47643979057591623, 0.375, 0.494949494949495, 1.0, 1.0, 0.4444444444444444, 0.38271604938271603, 0.4444444444444444, 0.42528735632183906, 1.0, 1.0, 1.0, 1.0, 0.4845360824742268, 0.4845360824742268, 1.0, 1.0, 0.45652173913043476, 1.0, 1.0, 1.0, 1.0, 0.48186528497409326, 0.453551912568306, 0.47368421052631576, 1.0, 0.4897959183673469, 1.0, 0.46808510638297873, 1.0, 0.48186528497409326, 1.0, 0.4594594594594595, 0.44751381215469616, 1.0, 1.0, 1.0, 0.49748743718592964, 1.0, 0.3939393939393939, 1.0, 0.49748743718592964, 1.0, 0.49238578680203043, 0.48186528497409326, 0.40828402366863903, 1.0, 0.494949494949495, 0.494949494949495, 1.0, 0.47643979057591623, 1.0, 0.494949494949495, 1.0, 0.494949494949495, 0.46808510638297873, 0.4897959183673469, 1.0, 1.0, 1.0, 0.4845360824742268, 1.0, 1.0, 0.45054945054945056, 0.46808510638297873, 1.0, 1.0, 1.0, 0.4897959183673469, 0.441340782122905, 1.0, 0.47368421052631576, 0.49748743718592964, 1.0, 0.46524064171123, 0.49748743718592964, 0.4845360824742268, 1.0, 0.46236559139784944, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.45054945054945056, 1.0, 1.0, 0.4845360824742268, 0.47643979057591623, 0.47368421052631576, 1.0, 0.494949494949495, 0.4845360824742268, 1.0, 0.49238578680203043, 1.0, 0.40476190476190477, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.494949494949495, 0.4791666666666667, 0.40828402366863903, 0.25925925925925924, 0.4318181818181818, 1.0, 1.0, 0.49748743718592964, 1.0, 0.46236559139784944, 1.0, 1.0, 0.43820224719101125, 1.0, 0.32653061224489793, 0.46236559139784944, 1.0, 0.46524064171123, 0.49748743718592964, 1.0, 1.0, 0.494949494949495, 1.0, 0.453551912568306, 0.46524064171123, 0.44751381215469616, 0.48717948717948717, 0.43820224719101125, 0.38271604938271603, 0.44751381215469616, 1.0, 0.49238578680203043, 0.4845360824742268, 1.0, 1.0, 1.0, 1.0, 0.4897959183673469, 1.0, 1.0, 1.0, 0.494949494949495, 0.494949494949495, 1.0, 0.4117647058823529, 1.0, 0.40119760479041916, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.494949494949495, 0.49748743718592964, 0.45652173913043476, 1.0, 0.4845360824742268, 1.0, 1.0, 1.0, 1.0, 0.39759036144578314, 0.494949494949495, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.494949494949495, 0.46808510638297873, 1.0, 1.0, 1.0, 0.43820224719101125, 1.0, 1.0, 0.49238578680203043, 1.0, 1.0, 0.49238578680203043, 1.0, 0.494949494949495, 1.0, 0.4791666666666667, 1.0, 1.0, 1.0, 1.0, 1.0, 0.49748743718592964, 0.40119760479041916, 1.0, 1.0, 1.0, 0.4845360824742268, 1.0, 0.46236559139784944, 1.0, 1.0, 1.0, 0.494949494949495, 1.0, 0.49238578680203043, 0.4845360824742268, 1.0, 1.0, 0.49748743718592964, 1.0, 0.4845360824742268, 0.46524064171123, 0.42196531791907516, 1.0, 0.4444444444444444, 1.0, 1.0, 1.0, 1.0, 0.494949494949495, 1.0, 0.494949494949495, 1.0, 1.0, 0.494949494949495, 0.48717948717948717, 0.494949494949495, 1.0, 0.45652173913043476, 0.4845360824742268, 1.0, 0.3282571912013536, 1.0, 1.0, 1.0, 0.42528735632183906, 1.0, 0.4897959183673469, 1.0, 1.0, 0.4845360824742268, 1.0, 1.0, 1.0, 0.47368421052631576, 0.49748743718592964, 1.0, 1.0, 0.48186528497409326, 0.4594594594594595, 1.0, 1.0, 1.0, 1.0, 1.0, 0.45054945054945056, 0.494949494949495, 0.4897959183673469, 0.49238578680203043, 1.0, 1.0, 1.0, 0.45652173913043476, 1.0, 1.0, 0.4897959183673469, 1.0, 1.0, 1.0, 0.3230240549828179, 0.48186528497409326, 0.42528735632183906, 1.0, 1.0, 1.0, 0.3043478260869565, 1.0, 1.0, 0.494949494949495, 0.494949494949495, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4444444444444444, 1.0, 1.0, 0.4845360824742268, 0.4897959183673469, 0.48186528497409326, 0.46524064171123, 0.494949494949495, 1.0, 1.0, 0.4791666666666667, 0.46236559139784944, 1.0, 0.4897959183673469, 0.48186528497409326, 0.4845360824742268, 1.0, 1.0, 0.46236559139784944, 0.47368421052631576, 1.0, 0.49748743718592964, 1.0, 0.4791666666666667, 1.0, 0.494949494949495, 0.494949494949495, 0.47643979057591623, 1.0, 1.0, 0.494949494949495, 0.48717948717948717, 1.0, 0.47368421052631576, 0.441340782122905, 0.45652173913043476, 1.0, 1.0, 0.40476190476190477, 1.0, 0.4594594594594595, 1.0, 1.0, 0.46236559139784944, 1.0, 0.4845360824742268, 1.0, 0.39759036144578314, 1.0, 1.0, 1.0, 1.0, 0.47368421052631576, 0.46524064171123, 1.0, 0.4897959183673469, 1.0, 1.0, 0.45054945054945056, 1.0, 0.4791666666666667, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4897959183673469, 0.46236559139784944, 0.46236559139784944, 0.494949494949495, 0.494949494949495, 0.4350282485875706, 1.0, 0.4845360824742268, 0.4845360824742268, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.46808510638297873, 0.4897959183673469, 0.49748743718592964, 1.0, 1.0, 1.0, 0.46808510638297873, 1.0, 0.46236559139784944, 1.0, 0.46808510638297873, 1.0, 1.0, 0.4897959183673469, 1.0, 1.0, 1.0, 0.48717948717948717, 0.49748743718592964, 1.0, 1.0, 1.0, 1.0, 0.47368421052631576, 1.0, 1.0, 0.4897959183673469, 0.47368421052631576, 0.453551912568306, 1.0, 0.49748743718592964, 1.0, 1.0, 0.47368421052631576, 1.0, 0.46808510638297873, 0.40828402366863903, 0.47368421052631576, 0.49748743718592964, 1.0, 1.0, 0.48186528497409326, 1.0, 1.0, 0.48717948717948717, 1.0, 1.0, 1.0, 0.4897959183673469, 1.0, 0.4897959183673469, 1.0, 0.49238578680203043, 1.0, 1.0, 0.45652173913043476, 0.49238578680203043, 0.4350282485875706, 1.0, 0.47643979057591623, 1.0, 1.0, 0.3230240549828179, 1.0, 0.49238578680203043, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4897959183673469, 1.0, 1.0, 1.0, 1.0, 0.49238578680203043, 0.453551912568306, 1.0, 1.0, 1.0, 1.0, 1.0, 0.47368421052631576, 0.45054945054945056, 1.0, 0.4708994708994709, 1.0, 0.42528735632183906, 0.494949494949495, 1.0, 1.0, 0.48186528497409326, 1.0, 1.0, 0.40476190476190477, 0.4186046511627907, 0.494949494949495, 1.0, 0.49238578680203043, 0.4897959183673469, 1.0, 1.0, 1.0, 0.4897959183673469, 0.4845360824742268, 1.0, 1.0, 1.0, 0.494949494949495, 1.0, 0.42528735632183906, 1.0, 1.0, 1.0, 0.26506024096385544, 0.4845360824742268, 1.0, 1.0, 0.38650306748466257, 0.47368421052631576, 1.0, 1.0, 0.4897959183673469, 0.4897959183673469, 1.0, 0.494949494949495, 1.0, 1.0, 0.4897959183673469, 0.494949494949495, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4845360824742268, 1.0, 1.0, 0.49238578680203043, 1.0, 1.0, 1.0, 1.0, 0.44751381215469616, 0.46236559139784944, 1.0, 1.0, 0.46236559139784944, 1.0, 0.4897959183673469, 1.0, 1.0, 1.0, 0.37888198757763975, 1.0, 0.494949494949495, 0.4845360824742268, 1.0, 0.49748743718592964, 0.40476190476190477, 0.494949494949495, 1.0, 1.0, 0.4845360824742268, 1.0, 1.0, 0.48186528497409326, 1.0, 0.494949494949495, 0.2835249042145594, 0.46524064171123, 1.0, 1.0, 1.0, 1.0, 0.4845360824742268, 0.4152046783625731, 1.0, 0.4897959183673469, 0.4897959183673469, 0.494949494949495, 1.0, 0.46236559139784944, 0.4845360824742268, 0.45652173913043476, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.46236559139784944, 0.49748743718592964, 1.0, 0.47368421052631576, 1.0, 0.4897959183673469, 1.0, 1.0, 1.0, 0.49238578680203043, 0.4791666666666667, 1.0, 1.0, 1.0, 1.0, 0.4186046511627907, 1.0, 0.4845360824742268, 0.494949494949495, 0.4594594594594595, 1.0, 1.0, 0.46808510638297873, 1.0, 1.0, 0.4845360824742268, 1.0, 1.0, 1.0, 1.0, 0.4845360824742268, 0.494949494949495, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.49748743718592964, 1.0, 0.46808510638297873, 1.0, 0.46236559139784944, 0.4791666666666667, 0.47368421052631576, 1.0, 1.0, 0.494949494949495, 1.0, 0.40119760479041916, 0.494949494949495, 1.0, 1.0, 1.0, 0.46524064171123, 1.0, 1.0, 1.0, 1.0, 1.0, 0.494949494949495, 1.0, 0.46236559139784944, 1.0, 0.47643979057591623, 1.0, 1.0, 0.49238578680203043, 0.46524064171123, 1.0, 0.48717948717948717, 1.0, 1.0, 1.0, 0.4897959183673469, 0.48717948717948717, 0.4791666666666667, 1.0, 1.0, 1.0, 1.0, 0.47368421052631576, 1.0, 0.494949494949495, 1.0, 1.0, 0.45652173913043476, 1.0, 1.0, 0.4791666666666667, 0.4845360824742268, 0.494949494949495, 1.0, 0.42857142857142855, 1.0, 0.453551912568306, 0.47643979057591623, 1.0, 0.4791666666666667, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.23093681917211328, 0.4444444444444444, 0.4444444444444444, 0.49748743718592964, 1.0, 1.0, 0.494949494949495, 0.494949494949495, 0.4897959183673469, 1.0, 1.0, 1.0, 0.47368421052631576, 1.0, 0.47368421052631576, 1.0, 1.0, 1.0, 0.4845360824742268, 1.0, 1.0, 1.0, 1.0, 0.4897959183673469, 1.0, 1.0, 1.0, 0.47368421052631576, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.453551912568306, 1.0, 1.0, 0.453551912568306, 0.49748743718592964, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4318181818181818, 1.0, 0.4845360824742268, 1.0, 1.0, 0.4897959183673469, 0.4845360824742268, 1.0, 1.0, 1.0, 0.4791666666666667, 1.0, 0.4152046783625731, 0.3939393939393939, 0.49238578680203043, 1.0, 1.0, 1.0, 1.0, 0.4845360824742268, 1.0, 0.31393298059964725, 1.0, 0.494949494949495, 0.49238578680203043, 1.0, 1.0, 0.49238578680203043, 1.0, 1.0, 1.0, 0.43820224719101125, 1.0, 1.0, 0.46808510638297873, 0.3230240549828179, 1.0, 0.46808510638297873, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4444444444444444, 1.0, 0.4350282485875706, 1.0, 1.0, 0.32124352331606215, 1.0, 1.0, 0.4350282485875706, 1.0, 1.0, 0.46524064171123, 1.0, 0.4594594594594595, 0.46236559139784944, 0.358974358974359, 0.4845360824742268, 0.46236559139784944, 1.0, 1.0, 0.4708994708994709, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.46236559139784944, 1.0, 1.0, 0.46236559139784944, 0.49238578680203043, 1.0, 1.0, 0.40476190476190477, 1.0, 1.0, 1.0, 1.0, 0.4845360824742268, 1.0, 0.46808510638297873, 1.0, 1.0, 0.4594594594594595, 1.0, 1.0, 1.0, 0.494949494949495, 1.0, 1.0, 0.49748743718592964, 1.0, 1.0, 0.47643979057591623, 1.0, 0.46236559139784944, 1.0, 1.0, 1.0, 0.4791666666666667, 0.46236559139784944, 1.0, 0.39759036144578314, 1.0, 0.3194444444444445, 1.0, 0.46236559139784944, 1.0, 1.0, 1.0, 0.4708994708994709, 1.0, 0.47643979057591623, 0.4791666666666667, 0.46808510638297873, 0.494949494949495, 1.0, 1.0, 0.4791666666666667, 1.0, 0.42857142857142855, 1.0, 1.0, 1.0, 1.0, 0.49748743718592964, 1.0, 0.43820224719101125, 0.494949494949495, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.39759036144578314, 1.0, 1.0, 1.0, 1.0, 1.0, 0.46236559139784944, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3157894736842105, 0.47368421052631576, 1.0, 0.49748743718592964, 1.0, 1.0, 0.45054945054945056, 0.47643979057591623, 1.0, 0.46236559139784944, 1.0, 1.0, 0.4444444444444444, 1.0, 0.4791666666666667, 0.46808510638297873, 1.0, 0.4845360824742268, 1.0, 1.0, 0.494949494949495, 1.0, 1.0, 0.47368421052631576, 0.441340782122905, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4444444444444444, 1.0, 1.0, 0.43820224719101125, 1.0, 1.0, 1.0, 1.0, 0.4845360824742268, 0.49238578680203043, 1.0, 0.4845360824742268, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4845360824742268, 1.0, 0.494949494949495, 1.0, 1.0, 0.49748743718592964, 0.46236559139784944, 0.494949494949495, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4350282485875706, 1.0, 0.42528735632183906, 0.4845360824742268, 1.0, 1.0, 0.4845360824742268, 1.0, 1.0, 0.4897959183673469, 1.0, 1.0, 1.0, 0.494949494949495, 1.0, 0.494949494949495, 1.0, 0.4594594594594595, 1.0, 0.4897959183673469, 1.0, 1.0, 1.0, 0.45054945054945056, 1.0, 0.42857142857142855, 0.4791666666666667, 0.494949494949495, 0.4791666666666667, 1.0, 1.0, 1.0, 0.4897959183673469, 1.0, 0.46808510638297873, 0.48717948717948717, 1.0, 0.49748743718592964, 1.0, 1.0, 0.42196531791907516, 1.0, 1.0, 1.0, 1.0, 0.3939393939393939, 1.0, 1.0, 1.0, 0.46236559139784944, 0.4845360824742268, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.47643979057591623, 1.0, 1.0, 1.0, 0.4897959183673469, 0.4708994708994709, 1.0, 0.494949494949495, 1.0, 0.49748743718592964, 1.0, 1.0, 0.46236559139784944, 1.0, 0.49238578680203043, 1.0, 1.0, 1.0, 0.4897959183673469, 0.45652173913043476, 1.0, 1.0, 0.46524064171123, 1.0, 1.0, 0.42857142857142855, 0.4897959183673469, 1.0, 1.0, 1.0, 1.0, 0.46236559139784944, 1.0, 1.0, 1.0, 1.0, 1.0, 0.42528735632183906, 0.494949494949495, 0.49238578680203043, 1.0, 1.0, 0.4845360824742268, 1.0, 0.40476190476190477, 0.494949494949495, 0.494949494949495, 0.4897959183673469, 1.0, 1.0, 1.0, 0.4845360824742268, 0.4897959183673469, 0.494949494949495, 1.0, 0.46808510638297873, 1.0, 1.0, 0.4708994708994709, 0.34210526315789475, 1.0, 0.4845360824742268, 0.46524064171123, 1.0, 1.0, 0.42528735632183906, 1.0, 0.49748743718592964, 1.0, 1.0, 1.0, 0.49238578680203043, 1.0, 0.42857142857142855, 1.0, 0.45652173913043476, 0.4897959183673469, 1.0, 0.494949494949495, 1.0, 1.0, 1.0, 0.43820224719101125, 0.46524064171123, 1.0, 1.0, 1.0, 0.49238578680203043, 0.46524064171123, 1.0, 0.39759036144578314, 0.42196531791907516, 1.0, 1.0, 1.0, 0.494949494949495, 1.0, 1.0, 1.0, 0.494949494949495, 0.45054945054945056, 0.48186528497409326, 0.4117647058823529, 1.0, 1.0, 0.4117647058823529, 0.48186528497409326, 0.494949494949495, 1.0, 0.47368421052631576, 1.0, 0.4791666666666667, 1.0, 1.0, 0.494949494949495, 1.0, 1.0, 1.0, 1.0, 0.47368421052631576, 1.0, 0.494949494949495, 1.0, 1.0, 0.4791666666666667, 1.0, 0.494949494949495, 0.494949494949495, 1.0, 0.49748743718592964, 0.46808510638297873, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.494949494949495, 1.0, 0.49238578680203043, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.47643979057591623, 0.48717948717948717, 0.4845360824742268, 1.0, 1.0, 1.0, 0.4845360824742268, 0.3902439024390244, 0.48186528497409326, 0.46524064171123, 1.0, 1.0, 0.4708994708994709, 1.0, 0.4845360824742268, 0.35064935064935066, 1.0, 1.0, 1.0, 0.40828402366863903, 0.4897959183673469, 1.0, 1.0, 0.4444444444444444, 1.0, 1.0, 0.4791666666666667, 1.0, 0.45054945054945056, 1.0, 1.0, 0.45652173913043476, 1.0, 0.4444444444444444, 1.0, 0.49748743718592964, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.46236559139784944, 1.0, 1.0, 1.0, 1.0, 0.39759036144578314, 1.0, 0.47368421052631576, 1.0, 1.0, 0.47368421052631576, 1.0, 1.0, 1.0, 0.47643979057591623, 1.0, 1.0, 1.0, 1.0, 0.46524064171123, 0.4845360824742268, 1.0, 1.0, 0.4897959183673469, 1.0, 0.47643979057591623, 0.494949494949495, 1.0, 1.0, 1.0, 1.0, 0.494949494949495, 1.0, 1.0, 1.0, 1.0, 0.4117647058823529, 0.494949494949495, 0.46236559139784944, 1.0, 1.0, 1.0, 0.48186528497409326, 0.494949494949495, 0.46808510638297873, 1.0, 0.4897959183673469, 0.494949494949495, 0.42857142857142855, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4444444444444444, 0.42196531791907516, 1.0, 1.0, 0.4708994708994709, 1.0, 0.49748743718592964, 1.0, 1.0, 0.49748743718592964, 1.0, 0.43820224719101125, 0.47643979057591623, 1.0, 1.0, 1.0, 1.0, 0.4444444444444444, 1.0, 1.0, 1.0, 1.0, 0.43820224719101125, 0.4897959183673469, 1.0, 1.0, 0.441340782122905, 0.494949494949495, 0.46808510638297873, 1.0, 0.46524064171123, 1.0, 1.0, 1.0, 1.0, 0.494949494949495, 1.0, 0.3670886075949367, 0.494949494949495, 0.4845360824742268, 0.46524064171123, 1.0, 1.0, 0.49748743718592964, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.49238578680203043, 1.0, 1.0, 0.4845360824742268, 0.4152046783625731, 1.0, 0.47368421052631576, 1.0, 1.0, 0.494949494949495, 1.0, 1.0, 0.494949494949495, 1.0, 0.4791666666666667, 0.494949494949495, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.494949494949495, 1.0, 0.46524064171123, 1.0, 1.0, 1.0, 0.39759036144578314, 0.49748743718592964, 1.0, 0.3670886075949367, 0.494949494949495, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.45652173913043476, 1.0, 1.0, 0.47368421052631576, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.494949494949495, 1.0, 1.0, 0.494949494949495, 1.0, 1.0, 1.0, 1.0, 1.0, 0.494949494949495, 1.0, 0.45652173913043476, 1.0, 1.0, 0.4897959183673469, 1.0, 1.0, 0.494949494949495, 1.0, 0.46236559139784944, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4791666666666667, 1.0, 0.43820224719101125, 1.0, 1.0, 0.49238578680203043, 1.0, 0.45054945054945056, 1.0, 1.0, 0.42528735632183906, 0.49238578680203043, 1.0, 1.0, 0.4897959183673469, 0.46808510638297873, 0.46236559139784944, 1.0, 1.0, 0.45652173913043476, 0.46808510638297873, 0.4444444444444444, 1.0, 0.4845360824742268, 1.0, 1.0, 1.0, 0.49748743718592964, 1.0, 1.0, 1.0, 1.0, 0.49238578680203043, 1.0, 1.0, 0.4897959183673469, 1.0, 1.0, 0.49748743718592964, 1.0, 1.0, 0.49748743718592964, 1.0, 0.45652173913043476, 1.0, 1.0, 0.43820224719101125, 0.48717948717948717, 1.0, 1.0]\n",
      "Mean F1-Score: 0.6807268204212521\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Sequence-level F1-Score 계산\n",
    "f1_scores = []\n",
    "for true_seq, pred_seq in zip(y_test_concat, y_pred_classes):\n",
    "    f1 = f1_score(true_seq, pred_seq, average='macro')  # 시퀀스마다 F1-score 계산\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "# 시퀀스 별 F1 스코어 출력\n",
    "print(f\"F1-Scores for each sequence: {f1_scores}\")\n",
    "# 평균 F1-score\n",
    "print(f\"Mean F1-Score: {np.mean(f1_scores)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anomaly_detection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
